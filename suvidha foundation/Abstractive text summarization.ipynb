{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"mount_file_id":"184wodvMJsWH4K69wxRbJLT-4-WjSB74K","authorship_tag":"ABX9TyNYvv6cLQcLaxhWDzXeKHiH"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","gpuClass":"standard","widgets":{"application/vnd.jupyter.widget-state+json":{"9e3751e9fced48018609536e1ac73d02":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_14cdc93700ee4a89812e1153db0da2db","IPY_MODEL_9f5d7a5d73244606a2d7c6eeab4d6389","IPY_MODEL_0386a584ad104e93ab24b126ef210929"],"layout":"IPY_MODEL_b8e9ed0f708a4f009fde8c555730438e"}},"14cdc93700ee4a89812e1153db0da2db":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_5efd0a971bc042bf858b8fcda8398856","placeholder":"​","style":"IPY_MODEL_f23c474281b3485db73ab831eb9a5b96","value":"Downloading: 100%"}},"9f5d7a5d73244606a2d7c6eeab4d6389":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_2badfd63bc33448b8dcd3d1813dfde12","max":1585,"min":0,"orientation":"horizontal","style":"IPY_MODEL_e806e59430be48e69614fda09d11ef00","value":1585}},"0386a584ad104e93ab24b126ef210929":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_9022b8782c4d43edbc5973c8ed05903a","placeholder":"​","style":"IPY_MODEL_0d3771da273d421c87fb34f70d4cc6c9","value":" 1.58k/1.58k [00:00&lt;00:00, 53.2kB/s]"}},"b8e9ed0f708a4f009fde8c555730438e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5efd0a971bc042bf858b8fcda8398856":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f23c474281b3485db73ab831eb9a5b96":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"2badfd63bc33448b8dcd3d1813dfde12":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e806e59430be48e69614fda09d11ef00":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"9022b8782c4d43edbc5973c8ed05903a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0d3771da273d421c87fb34f70d4cc6c9":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"5cf6cdc1d2934376bb297c3f059d42b1":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_baf51852b59040f996aa56893af13d4c","IPY_MODEL_83372097343d4ae499e9d6892efbcab5","IPY_MODEL_6a18b32d150649acb6025df353f6370f"],"layout":"IPY_MODEL_333ea7ab69a64111aa6e78c2ea567a80"}},"baf51852b59040f996aa56893af13d4c":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_70735f1ac28d4879952da311964ea4fa","placeholder":"​","style":"IPY_MODEL_5bde174e1f9b4f68b1f2f513cd33047b","value":"Downloading: 100%"}},"83372097343d4ae499e9d6892efbcab5":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_340a51908117493ba593a2685b15135c","max":1625270765,"min":0,"orientation":"horizontal","style":"IPY_MODEL_9a9292b8567a49f28e70f5c28f4e459b","value":1625270765}},"6a18b32d150649acb6025df353f6370f":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d7b1cc4b5bfe437b878600364a811346","placeholder":"​","style":"IPY_MODEL_ebef1fec7eef40e398fb0543db8475cf","value":" 1.63G/1.63G [00:42&lt;00:00, 41.5MB/s]"}},"333ea7ab69a64111aa6e78c2ea567a80":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"70735f1ac28d4879952da311964ea4fa":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5bde174e1f9b4f68b1f2f513cd33047b":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"340a51908117493ba593a2685b15135c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9a9292b8567a49f28e70f5c28f4e459b":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"d7b1cc4b5bfe437b878600364a811346":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ebef1fec7eef40e398fb0543db8475cf":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"7db18d8c1c7243dfa9fb4696cb508a49":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_6f49171111d448bcabc523b04064314d","IPY_MODEL_93482c1041654798a56f21bce0bb3d15","IPY_MODEL_d046abc1345b42048d62735beca3dba1"],"layout":"IPY_MODEL_b13aa75e4e694eb5b03929865c544a9d"}},"6f49171111d448bcabc523b04064314d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_9ad151907d2345698b2c344aa1950921","placeholder":"​","style":"IPY_MODEL_27c72d370f3a4fe1afb475d3b3187c66","value":"Downloading: 100%"}},"93482c1041654798a56f21bce0bb3d15":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_591ccea08d6a453f98255b6467487f72","max":898823,"min":0,"orientation":"horizontal","style":"IPY_MODEL_7a826eeac40c4d1eaf445636709c348d","value":898823}},"d046abc1345b42048d62735beca3dba1":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_669254a5f067401cab010a6eec1e20c8","placeholder":"​","style":"IPY_MODEL_d3a6317d3f2b433fbb254586da8550a7","value":" 899k/899k [00:00&lt;00:00, 14.3MB/s]"}},"b13aa75e4e694eb5b03929865c544a9d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9ad151907d2345698b2c344aa1950921":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"27c72d370f3a4fe1afb475d3b3187c66":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"591ccea08d6a453f98255b6467487f72":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7a826eeac40c4d1eaf445636709c348d":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"669254a5f067401cab010a6eec1e20c8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d3a6317d3f2b433fbb254586da8550a7":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"6c1f20f326354618a51b12c3397ae1cb":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_1cab0526ae6c46ae9daae2b5985140e9","IPY_MODEL_32ac4e531e3b4968b395967846b0a127","IPY_MODEL_969437f97b654970a28f6023b2c8aa12"],"layout":"IPY_MODEL_88388100f7ee4723b40b63fd95abf3cb"}},"1cab0526ae6c46ae9daae2b5985140e9":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_421af5a880004007844e1524cfcfeb0b","placeholder":"​","style":"IPY_MODEL_ee7c7e5732584a1cba5f0ee6d74b1c9e","value":"Downloading: 100%"}},"32ac4e531e3b4968b395967846b0a127":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_5ef2907a0e684bcfb092105955bc06f2","max":456318,"min":0,"orientation":"horizontal","style":"IPY_MODEL_2c244c4a45c7412296b95a2c4e2e904f","value":456318}},"969437f97b654970a28f6023b2c8aa12":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_cd97c379ed404e958ef688cae24f01c7","placeholder":"​","style":"IPY_MODEL_d9c05f92b4c14eb6951372a036cf555f","value":" 456k/456k [00:00&lt;00:00, 5.59MB/s]"}},"88388100f7ee4723b40b63fd95abf3cb":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"421af5a880004007844e1524cfcfeb0b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ee7c7e5732584a1cba5f0ee6d74b1c9e":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"5ef2907a0e684bcfb092105955bc06f2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2c244c4a45c7412296b95a2c4e2e904f":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"cd97c379ed404e958ef688cae24f01c7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d9c05f92b4c14eb6951372a036cf555f":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"cells":[{"cell_type":"markdown","source":["# Text Summarization using Extractive and Abstractive methods"],"metadata":{"id":"YdOqo7borW3x"}},{"cell_type":"markdown","source":["## Text summarization using the Extractive method\n","\n","In this notebook we will be using the Latent semantic analysis for extractive summarization."],"metadata":{"id":"jQtYEFAnrCiW"}},{"cell_type":"markdown","source":["### Importing the required packages\n","\n","* Pandas and numpy for data manipulation and data reterival techniques, also for creating data-frames.\n","* Matplotlib for visualizing the trends in the data.\n","* For dimensionality reduction, import the TruncatedSVD (Singular value decomposition) usually for analysis for the most frequent and weighted terms based on the Term-frequency inverse document frequency (Tfidf) vectorizer.\n","* Regular expressions for preprocessing the textual data.\n","* For removing the stopwords from the cropus, import the stopwords library from the nltk."],"metadata":{"id":"kVubQ1fFz9MM"}},{"cell_type":"code","source":["import pandas as pd\n","import numpy as np\n","from pandas import Series, DataFrame\n","\n","import matplotlib.pyplot as plt\n","\n","import re\n","import string\n","\n","import sklearn as sk\n","from sklearn.decomposition import TruncatedSVD\n","from sklearn.feature_extraction.text import TfidfVectorizer\n","\n","import nltk \n","from nltk.corpus import stopwords"],"metadata":{"id":"O6ldj1GprAq_","executionInfo":{"status":"ok","timestamp":1670992098807,"user_tz":-330,"elapsed":376,"user":{"displayName":"liyakhat yousuf","userId":"14707657332816345199"}}},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":["### Preprocessing the corpus\n","\n","* The below function is used for preprocessing the corpus by removing the punctuations, lowering the characters, tokenzing the words and removing the stopwords.\n","* By preprocessing we can get the most important terms in the document which are helpful in analysis and makes it more readable and understandable."],"metadata":{"id":"blS_U81H1p6c"}},{"cell_type":"code","source":["def text_preprocess(text):\n","    list_obj = \"\".join([char.lower() for char in text if char not in string.punctuation])\n","    tokenized = re.split('\\W+', list_obj)\n","    no_stopwords = \" \".join([word for word in tokenized if word not in stopwords.words('english')])\n","    return no_stopwords"],"metadata":{"id":"38GDsWIlxEdR","executionInfo":{"status":"ok","timestamp":1670992099216,"user_tz":-330,"elapsed":12,"user":{"displayName":"liyakhat yousuf","userId":"14707657332816345199"}}},"execution_count":7,"outputs":[]},{"cell_type":"markdown","source":["### Reading the data.\n","\n","* Reading the data and following the preprocessing steps."],"metadata":{"id":"UTzfbTfg2cSr"}},{"cell_type":"code","source":["corpus = open('/content/drive/MyDrive/Colab Notebooks/Python Data science /Python Scripts/Refactored_Py_DS_ML_Bootcamp-master/Natural language processing/document.txt', 'r').read()"],"metadata":{"id":"HHmuQl5HxEZy","executionInfo":{"status":"ok","timestamp":1670992100603,"user_tz":-330,"elapsed":1397,"user":{"displayName":"liyakhat yousuf","userId":"14707657332816345199"}}},"execution_count":8,"outputs":[]},{"cell_type":"code","source":["corpus_list = corpus.split('\\n')[:-6]\n","dataset = DataFrame(corpus_list, columns=['Text'])\n","dataset['Preprocessed'] = dataset['Text'].apply(lambda x: text_preprocess(x))"],"metadata":{"id":"X_LE_H9bxEXj","executionInfo":{"status":"ok","timestamp":1670992101084,"user_tz":-330,"elapsed":483,"user":{"displayName":"liyakhat yousuf","userId":"14707657332816345199"}}},"execution_count":9,"outputs":[]},{"cell_type":"markdown","source":["### Vectorizing the data"],"metadata":{"id":"qMGglNVJ2uH3"}},{"cell_type":"code","source":["tfidf = TfidfVectorizer()\n","vectors = tfidf.fit(dataset['Preprocessed'].tolist())\n","vectorized = tfidf.transform(dataset['Preprocessed'].tolist())\n","vectorized.todense()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8D5R4-1fxEU9","executionInfo":{"status":"ok","timestamp":1670992101084,"user_tz":-330,"elapsed":17,"user":{"displayName":"liyakhat yousuf","userId":"14707657332816345199"}},"outputId":"50b95e6d-b215-43f3-b7da-9e7d29477503"},"execution_count":10,"outputs":[{"output_type":"execute_result","data":{"text/plain":["matrix([[0.        , 0.10724106, 0.        , ..., 0.        , 0.        ,\n","         0.        ],\n","        [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n","         0.        ],\n","        [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n","         0.        ],\n","        ...,\n","        [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n","         0.        ],\n","        [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n","         0.13578852],\n","        [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n","         0.        ]])"]},"metadata":{},"execution_count":10}]},{"cell_type":"markdown","source":["### Singualar Value Decomposition (Latent semantic analysis)."],"metadata":{"id":"LTiJP_2m3WIt"}},{"cell_type":"code","source":["svd = TruncatedSVD(n_components=30, n_iter=150)\n","\n","decomposed = svd.fit_transform(vectorized)\n","\n","svd.components_"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qXvw9uzMxEP3","executionInfo":{"status":"ok","timestamp":1670992101085,"user_tz":-330,"elapsed":17,"user":{"displayName":"liyakhat yousuf","userId":"14707657332816345199"}},"outputId":"a316cb82-b08a-45a2-dda7-f934ea8d3078"},"execution_count":11,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[ 0.11061634,  0.01339401,  0.00489212, ...,  0.00489212,\n","         0.00489212,  0.01647105],\n","       [-0.12230496, -0.00932177, -0.00284044, ..., -0.00284044,\n","        -0.00284044,  0.02483275],\n","       [-0.01879132,  0.01345226, -0.0012168 , ..., -0.0012168 ,\n","        -0.0012168 , -0.01941212],\n","       ...,\n","       [-0.0311394 ,  0.03773901, -0.00457225, ..., -0.00457225,\n","        -0.00457225,  0.02410171],\n","       [ 0.00108786,  0.00508928, -0.01583101, ..., -0.01583101,\n","        -0.01583101, -0.06957262],\n","       [ 0.01534356, -0.0080803 , -0.00505606, ..., -0.00505606,\n","        -0.00505606,  0.00987365]])"]},"metadata":{},"execution_count":11}]},{"cell_type":"code","source":["terms = vectors.get_feature_names()\n","\n","for i, comp in enumerate(svd.components_):\n","  termsInComps = zip(terms, comp)\n","  sortedComp = sorted(termsInComps, key=lambda x: x[1], reverse=True)[:10]\n","  print(f'Concept {i + 1}:')\n","  for i in sortedComp:\n","    print(i[0])\n","  print()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"RH1urxxCxENM","executionInfo":{"status":"ok","timestamp":1670992101085,"user_tz":-330,"elapsed":14,"user":{"displayName":"liyakhat yousuf","userId":"14707657332816345199"}},"outputId":"3408959b-7437-44c2-f76d-e522b888f654"},"execution_count":12,"outputs":[{"output_type":"stream","name":"stdout","text":["Concept 1:\n","text\n","neural\n","summarization\n","network\n","data\n","recurrent\n","words\n","information\n","networks\n","new\n","\n","Concept 2:\n","network\n","neural\n","recurrent\n","feedback\n","problem\n","using\n","networks\n","gradient\n","loops\n","output\n","\n","Concept 3:\n","length\n","data\n","order\n","idea\n","sequences\n","sequenced\n","recordings\n","networks\n","varying\n","architecture\n","\n","Concept 4:\n","extractive\n","abstractive\n","model\n","ways\n","summary\n","words\n","proposed\n","rulings\n","creates\n","expressions\n","\n","Concept 5:\n","words\n","order\n","lyrics\n","much\n","come\n","advanced\n","new\n","normal\n","used\n","topic\n","\n","Concept 6:\n","model\n","proposed\n","numerous\n","texts\n","task\n","long\n","si\n","sequence\n","idea\n","paragraphs\n","\n","Concept 7:\n","sequences\n","may\n","want\n","input\n","additionally\n","affair\n","indeed\n","machine\n","operation\n","use\n","\n","Concept 8:\n","model\n","proposed\n","demonstrate\n","sequential\n","separate\n","text\n","architecture\n","dealt\n","new\n","used\n","\n","Concept 9:\n","learning\n","information\n","use\n","separate\n","sequence\n","additionally\n","affair\n","indeed\n","machine\n","operation\n","\n","Concept 10:\n","demanded\n","perform\n","numerous\n","true\n","bumps\n","cannot\n","capture\n","challenging\n","computations\n","dont\n","\n","Concept 11:\n","demonstrate\n","model\n","gradient\n","problem\n","vanishing\n","either\n","times\n","lstm\n","assessed\n","assessment\n","\n","Concept 12:\n","text\n","meaning\n","summary\n","perform\n","tries\n","employ\n","excerpts\n","existing\n","generate\n","guess\n","\n","Concept 13:\n","paragraphs\n","analogy\n","involves\n","nlp\n","architecture\n","dealt\n","generating\n","neural\n","texts\n","reading\n","\n","Concept 14:\n","task\n","numerous\n","accomplishing\n","another\n","considered\n","constant\n","continuous\n","despite\n","draws\n","formalized\n","\n","Concept 15:\n","true\n","tomorrow\n","long\n","events\n","happened\n","stored\n","delicate\n","using\n","mortal\n","demonstrate\n","\n","Concept 16:\n","additionally\n","indeed\n","machine\n","operation\n","affair\n","using\n","gradient\n","may\n","network\n","want\n","\n","Concept 17:\n","summary\n","used\n","provided\n","information\n","creating\n","possible\n","sentence\n","sentences\n","already\n","basically\n","\n","Concept 18:\n","document\n","field\n","future\n","research\n","summarized\n","outline\n","recent\n","bumps\n","cannot\n","capture\n","\n","Concept 19:\n","node\n","architecture\n","dealt\n","sequenced\n","true\n","sequential\n","delicate\n","separate\n","gradient\n","problem\n","\n","Concept 20:\n","recordings\n","proposed\n","general\n","delicate\n","need\n","audio\n","examples\n","real\n","video\n","world\n","\n","Concept 21:\n","important\n","way\n","provided\n","meaningful\n","used\n","still\n","possible\n","together\n","easily\n","amount\n","\n","Concept 22:\n","helpful\n","might\n","useful\n","text\n","fact\n","sentences\n","true\n","good\n","ways\n","summarized\n","\n","Concept 23:\n","ways\n","way\n","complex\n","computationally\n","expensive\n","puts\n","along\n","adds\n","set\n","knowledge\n","\n","Concept 24:\n","new\n","document\n","outline\n","model\n","methods\n","techniques\n","increase\n","advanced\n","recordings\n","sentence\n","\n","Concept 25:\n","possible\n","process\n","activation\n","loops\n","recurrent\n","collected\n","calls\n","case\n","current\n","encounter\n","\n","Concept 26:\n","topic\n","node\n","knowledge\n","lstm\n","report\n","advanced\n","provide\n","one\n","document\n","central\n","\n","Concept 27:\n","recurrent\n","dealing\n","possible\n","data\n","weights\n","activation\n","coefficients\n","exponential\n","loops\n","play\n","\n","Concept 28:\n","length\n","difficult\n","list\n","since\n","takes\n","traditional\n","vary\n","process\n","form\n","may\n","\n","Concept 29:\n","unroll\n","dealing\n","advanced\n","play\n","weight\n","topic\n","new\n","data\n","gradient\n","feedback\n","\n","Concept 30:\n","advanced\n","topic\n","prices\n","words\n","derived\n","finally\n","gives\n","semantic\n","network\n","new\n","\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.8/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n","  warnings.warn(msg, category=FutureWarning)\n"]}]},{"cell_type":"markdown","source":["## Text summarization using the Abstractive method\n","\n","In this notebook we will be using the BART algorithm for text summarization which has a pretrained model available in the hugging face package."],"metadata":{"id":"DEAqNvdX9eAO"}},{"cell_type":"markdown","source":["### Installing the required package\n","\n","The package used is the Transformers from the huggingface community. Which provides wide variety of packages for nlp and deep learning with pre-trained models available."],"metadata":{"id":"wukSju2uIdJG"}},{"cell_type":"code","execution_count":13,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7xHvR_ia9WC6","executionInfo":{"status":"ok","timestamp":1670992111457,"user_tz":-330,"elapsed":10382,"user":{"displayName":"liyakhat yousuf","userId":"14707657332816345199"}},"outputId":"cab9b214-0364-4fc8-ed68-eb689ee354da"},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting transformers\n","  Downloading transformers-4.25.1-py3-none-any.whl (5.8 MB)\n","\u001b[K     |████████████████████████████████| 5.8 MB 28.0 MB/s \n","\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.8/dist-packages (from transformers) (2022.6.2)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.8/dist-packages (from transformers) (6.0)\n","Collecting tokenizers!=0.11.3,<0.14,>=0.11.1\n","  Downloading tokenizers-0.13.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.6 MB)\n","\u001b[K     |████████████████████████████████| 7.6 MB 66.1 MB/s \n","\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.8/dist-packages (from transformers) (4.64.1)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from transformers) (3.8.0)\n","Collecting huggingface-hub<1.0,>=0.10.0\n","  Downloading huggingface_hub-0.11.1-py3-none-any.whl (182 kB)\n","\u001b[K     |████████████████████████████████| 182 kB 70.2 MB/s \n","\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from transformers) (2.23.0)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.8/dist-packages (from transformers) (1.21.6)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from transformers) (21.3)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.8/dist-packages (from huggingface-hub<1.0,>=0.10.0->transformers) (4.4.0)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (2022.9.24)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (3.0.4)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (1.24.3)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (2.10)\n","Installing collected packages: tokenizers, huggingface-hub, transformers\n","Successfully installed huggingface-hub-0.11.1 tokenizers-0.13.2 transformers-4.25.1\n"]}],"source":["pip install transformers"]},{"cell_type":"markdown","source":["### Importing the required packages.\n","\n","* We will be importing Bert from the transformers package.\n","* For data preprocessing we will be importing the regular expressions package.\n","\n","Using the BartForConditionalGeneration() function we can use the link of the pre-trained model from the huggingface community. \n","\n","We will then be creating a tokenizer which will be our pre-trained-model for encoding and decoding the data. \n"],"metadata":{"id":"2WXLN2NiJEFG"}},{"cell_type":"code","source":["from transformers import BartTokenizer, BartForConditionalGeneration, BartConfig\n","import re"],"metadata":{"id":"l3wrFYRs-NSP","executionInfo":{"status":"ok","timestamp":1670992116345,"user_tz":-330,"elapsed":4894,"user":{"displayName":"liyakhat yousuf","userId":"14707657332816345199"}}},"execution_count":14,"outputs":[]},{"cell_type":"code","source":["model = BartForConditionalGeneration.from_pretrained('facebook/bart-large-cnn')"],"metadata":{"id":"tXTXfhNXIqUz","executionInfo":{"status":"ok","timestamp":1670992164611,"user_tz":-330,"elapsed":48277,"user":{"displayName":"liyakhat yousuf","userId":"14707657332816345199"}},"colab":{"base_uri":"https://localhost:8080/","height":81,"referenced_widgets":["9e3751e9fced48018609536e1ac73d02","14cdc93700ee4a89812e1153db0da2db","9f5d7a5d73244606a2d7c6eeab4d6389","0386a584ad104e93ab24b126ef210929","b8e9ed0f708a4f009fde8c555730438e","5efd0a971bc042bf858b8fcda8398856","f23c474281b3485db73ab831eb9a5b96","2badfd63bc33448b8dcd3d1813dfde12","e806e59430be48e69614fda09d11ef00","9022b8782c4d43edbc5973c8ed05903a","0d3771da273d421c87fb34f70d4cc6c9","5cf6cdc1d2934376bb297c3f059d42b1","baf51852b59040f996aa56893af13d4c","83372097343d4ae499e9d6892efbcab5","6a18b32d150649acb6025df353f6370f","333ea7ab69a64111aa6e78c2ea567a80","70735f1ac28d4879952da311964ea4fa","5bde174e1f9b4f68b1f2f513cd33047b","340a51908117493ba593a2685b15135c","9a9292b8567a49f28e70f5c28f4e459b","d7b1cc4b5bfe437b878600364a811346","ebef1fec7eef40e398fb0543db8475cf"]},"outputId":"8141b190-18c0-4f94-fb75-e01ba9797932"},"execution_count":15,"outputs":[{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/1.58k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9e3751e9fced48018609536e1ac73d02"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/1.63G [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5cf6cdc1d2934376bb297c3f059d42b1"}},"metadata":{}}]},{"cell_type":"code","source":["tokenizer = BartTokenizer.from_pretrained('facebook/bart-large-cnn')"],"metadata":{"id":"n0xFcl1yJCWS","executionInfo":{"status":"ok","timestamp":1670992165456,"user_tz":-330,"elapsed":871,"user":{"displayName":"liyakhat yousuf","userId":"14707657332816345199"}},"colab":{"base_uri":"https://localhost:8080/","height":81,"referenced_widgets":["7db18d8c1c7243dfa9fb4696cb508a49","6f49171111d448bcabc523b04064314d","93482c1041654798a56f21bce0bb3d15","d046abc1345b42048d62735beca3dba1","b13aa75e4e694eb5b03929865c544a9d","9ad151907d2345698b2c344aa1950921","27c72d370f3a4fe1afb475d3b3187c66","591ccea08d6a453f98255b6467487f72","7a826eeac40c4d1eaf445636709c348d","669254a5f067401cab010a6eec1e20c8","d3a6317d3f2b433fbb254586da8550a7","6c1f20f326354618a51b12c3397ae1cb","1cab0526ae6c46ae9daae2b5985140e9","32ac4e531e3b4968b395967846b0a127","969437f97b654970a28f6023b2c8aa12","88388100f7ee4723b40b63fd95abf3cb","421af5a880004007844e1524cfcfeb0b","ee7c7e5732584a1cba5f0ee6d74b1c9e","5ef2907a0e684bcfb092105955bc06f2","2c244c4a45c7412296b95a2c4e2e904f","cd97c379ed404e958ef688cae24f01c7","d9c05f92b4c14eb6951372a036cf555f"]},"outputId":"117eb0cd-3036-44f9-88cd-443d5cd2b557"},"execution_count":16,"outputs":[{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/899k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7db18d8c1c7243dfa9fb4696cb508a49"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/456k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6c1f20f326354618a51b12c3397ae1cb"}},"metadata":{}}]},{"cell_type":"markdown","source":["### Functions for the required summarization.\n","\n","* preprocess_data - Takes parameters: Document.\n","* segment_data - Takes parameters: integer n, Document. \n","* pipeline - Takes parameters: integer n, segmented data. "],"metadata":{"id":"JDOXdwzfMIXn"}},{"cell_type":"markdown","source":["Function for removing the line breaks and special characters for the corpus."],"metadata":{"id":"RYzP10jYiUrL"}},{"cell_type":"code","source":["def preprocess_data(corpus: str):\n","  doc_list = re.split('\\n+', corpus)\n","  long_text = \"\".join(doc_list)\n","  preprocessed_data = \" \".join(re.split('\\W+', long_text))\n","  return preprocessed_data"],"metadata":{"id":"JTesLOxeL1y3","executionInfo":{"status":"ok","timestamp":1670992165457,"user_tz":-330,"elapsed":12,"user":{"displayName":"liyakhat yousuf","userId":"14707657332816345199"}}},"execution_count":17,"outputs":[]},{"cell_type":"markdown","source":["Used for dividing the corpus into equal segments for tokenizing. As the pre-trained model has limited id generation (which is 1024) hence we need to limit the data input for tokenizing. so we are segmenting the data into equal paritions based on the input parameter."],"metadata":{"id":"HSiYZUNoibnk"}},{"cell_type":"code","source":["def segment_data(n: int, data: str):\n","  segmented_data = []\n","  length = int(len(data) / n)\n","  for i in range(n):\n","    if i == 0:\n","      segmented_data.append(data[:length])\n","    else:\n","      segmented_data.append(data[length * i: (i + 1) * length])\n","\n","  return segmented_data"],"metadata":{"id":"2lTVSerjL1u4","executionInfo":{"status":"ok","timestamp":1670992165457,"user_tz":-330,"elapsed":11,"user":{"displayName":"liyakhat yousuf","userId":"14707657332816345199"}}},"execution_count":18,"outputs":[]},{"cell_type":"markdown","source":["Pipeline function helps in generating the summaries for the segmented corpus."],"metadata":{"id":"OJpBraGJieVD"}},{"cell_type":"code","source":["def pipeline(n: int, data):\n","  summaries = []\n","  for i in range(n):\n","    tokens = tokenizer([data[i]], return_tensors='pt')\n","    id_generation = model.generate(tokens['input_ids'], max_length=500, early_stopping=False)\n","    summaries.append([tokenizer.decode(id, skip_special_tokens=True) for id in id_generation])\n","  \n","  return summaries"],"metadata":{"id":"_I0iiC5BL1rn","executionInfo":{"status":"ok","timestamp":1670992165458,"user_tz":-330,"elapsed":10,"user":{"displayName":"liyakhat yousuf","userId":"14707657332816345199"}}},"execution_count":19,"outputs":[]},{"cell_type":"markdown","source":["Comparision function helps in getting the detalied view of the original data and summarized data."],"metadata":{"id":"lT4wvL-k4ReG"}},{"cell_type":"code","source":["  def comparision(n, original_data, summarized_data):\n","    print(\"\\nLength of Segmented Documents vs Length of Summaries\")\n","    for i in range(n):\n","      print(f\"Document - {i + 1} ---- {len(original_data[i])}\\t\\tSummary - {i + 1} ---- {len(summarized_data[i][0])}\")\n","    return original_data, \"\\n\",summarized_data"],"metadata":{"id":"Kw07aXUImcTU","executionInfo":{"status":"ok","timestamp":1670992165458,"user_tz":-330,"elapsed":9,"user":{"displayName":"liyakhat yousuf","userId":"14707657332816345199"}}},"execution_count":20,"outputs":[]},{"cell_type":"markdown","source":["### Reading the document\n","\n","* The document input can be given with the help of a text document stored in the google drive. The text document should be around 2000 words.\n","\n","* This data will then be going through series of functions to summarize the text.\n","* Depending on the segments of the data specified, the execution of pipeline function will vary. (execution takes around 1 - 3 minutes)"],"metadata":{"id":"cDHLkCVIK4Jd"}},{"cell_type":"code","source":["document = open('/content/drive/MyDrive/Colab Notebooks/Python Data science /Python Scripts/Refactored_Py_DS_ML_Bootcamp-master/Natural language processing/document.txt', 'r').read()"],"metadata":{"id":"fTfXsFdNJOrX","executionInfo":{"status":"ok","timestamp":1670992165458,"user_tz":-330,"elapsed":9,"user":{"displayName":"liyakhat yousuf","userId":"14707657332816345199"}}},"execution_count":21,"outputs":[]},{"cell_type":"code","source":["preprocessed = preprocess_data(document)\n","segmented_data = segment_data(n=3, data=preprocessed)\n","summarized = pipeline(n=3, data=segmented_data)\n","comparision(n=3, original_data=segmented_data, summarized_data=summarized)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"b9vbo3UM94QL","executionInfo":{"status":"ok","timestamp":1670992247960,"user_tz":-330,"elapsed":82510,"user":{"displayName":"liyakhat yousuf","userId":"14707657332816345199"}},"outputId":"8f667158-cea5-4dbd-8655-764cf8b8bbc5"},"execution_count":22,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","Length of Segmented Documents vs Length of Summaries\n","Document - 1 ---- 4095\t\tSummary - 1 ---- 533\n","Document - 2 ---- 4095\t\tSummary - 2 ---- 546\n","Document - 3 ---- 4095\t\tSummary - 3 ---- 698\n"]},{"output_type":"execute_result","data":{"text/plain":["(['Text summarization is an NLP grounded fashion which involves converting large number of paragraphs into simple accessible judgment done by involving various grammatical connections sentence matching etc Analogy of the original paragraphs or texts is maintained Let s say that we are reading a review or newspaper or some kind of research paper where you come across huge paragraphs This becomes a tedious task for anyone who just want to focus on the main context of what they are reading and save their time NLP involves creation of analogy and generating the texts This method of generating the texts should be ensured that verbatim is not occurring Verbatim is basically called as the words that already have been used in the original paragraph or text should not be used again We can ensure the percentage of the words that can be used in creating the summary By text summarization we easily filter out the main context of any content provided and take meaning full actions with that summary As we humans can consume a finite amount of information provided at times it is important for the summarizers for deriving to meaningful conclusions with as minimum noise as possible Text summarization is helpful in providing useful information from the text documents given spending less time in reading and getting useful information News articles fact sheets and mails fall under these categories Sentences builds upon the previous text summarization may not be helpful Research journals medical text are a good example where text summarizations are not very accurate The summarized texts might help us giving the summarized results but they might lack the style and tone of the text that the author tries to convey In text summarization the most important information of an original document is summarized in a way so that the main points of the document can be easily summarized Multi document summarization aims to produce a concentrated version of the document while keeping the key information Due to the massive amount of data available these days summarization has become increasingly important As a final note this paper is collected and the most recent and research in the field of text summarization to study and analyze for future research happens In the future it will provide a new direction for those who are interested in this field There s a huge quantum of data surfacing digitally thus the significance of developing a punctuate procedure to dock long textbooks incontinently while keeping the main idea of it is necessary Summarization helps mitigate the time needed for reading provide quick search for information and to help get the most desired information on the topic The central object of motorized textbook summarization is dwindling the reference textbook into a lower interpretation maintaining its knowledge alongside with its meaning Several descriptions of text summarization are provided for example explained the report as text that is generated from one or more documents that communicate relevant knowledge in the first text and that is no higher than half of the primary text and usually significantly more limited than that Then again it has been seen that the summarization task with different kinds has not been formalized as a multitarget streamlining task previously despite that there are numerous goals which can be considered The SI was not used before to help the continuous synopsis that draws near Subsequently another model has been proposed to be satisfactory for accomplishing numerous targets and to fulfil the constant needs In the long run this investigation will enthuse analysts to further consider the different sorts of SI when tackling the synopsis assignments especially in the short content outline field There is a huge amount of data surfacing digitally therefore the importance of developing a punctuate procedure to shorten long texts immediately while keeping the main idea of it is necessary Summarization also helps dock the time demanded for reading fasten the hunt for information and help to get the most quantum of informati',\n","  'on on one content Text summarization is a fascinating literacy content that caught attention fleetly as exploration increase they re hoping to witness a advance that will affect this by furnishing immediate method in summarizing long texts The swell of information available through the internet and social networks and information technologies make the need of summarization more critical especially with the massive quantum of data that s being spread due to the knowledge transfer among its druggies which makes it delicate to separate between the right information from the wrong bones There are two principles for the textbook summarization systems extractive and abstractive Extractive summarization creates synopsis by choosing remarkable rulings or expressions from the source content while abstractive strategies paraphrase and rebuild rulings to form the summary They concentrate around abstractive summarization in this work as it s decreasingly adaptable and hence can produce precipitously different summaries Recent neural system ways to deal with an outline are generally either sentence extractive choosing a lot of sentences as the summary or abstractive creating the summary from a seq2seq model In this work they present a neural model for single record summary dependent on joint extraction and pressure Following latterly fruitful extractive models they outline the summarization issues as a progression of original choices This model picks sentences from the report and after that chooses which of a set of compression options to apply to each chosen sentence They cipher this arrangement of separate contraction rules dependent on syntactic constituency parses still the proposed methodology is measured and it could use for any accessible source of condensing For learning they build oracle extractive compressive summaries that reflect vulnerability over the proposed model s decision sequence and then learn both parts together with this supervision Test results on the CNN Daily Mail and New York Times datasets demonstrate that this model accomplishes the innovative prosecution on substance determination assessed by Cream either mortal and homemade assessment demonstrate that the proposed model s yield for the utmost part remains The main topic of summarization has finally come into play Abstractive text summarization is used in the advanced text summarization methods where new words are derived from the given words in the document These new words gives much more meaning and semantic to the summarized topic Hence generating these new words are advanced techniques Abstractive text summarization methods employ more powerful natural language processing techniques to interpret text and generate new summary text as opposed to selecting the most representative existing excerpts to perform the summarization On the other hand it tries to guess the meaning of the whole textbook and presents the meaning to you It creates words and expressions puts them together in a meaningful way and along with that adds the most important data set up in the textbook This way abstractive summarization ways are more complex than extractive summarization ways and are also computationally expensive While both are valid approaches to textbook summarization it shouldn t be delicate to move you that abstractive ways are far more delicate to apply In fact the maturity of summarization processes moment are birth grounded This does not mean that abstractive styles should be blinked or ignored on the negative exploration into their perpetration and true semantic understanding of mortal language in general is a good pursuit and important work is demanded before we can confidently say that we ve gained a true base in this bid Sequenced data is data that takes the form of a list of varying length Sequences can be difficult for traditional neural networks to process since there is the idea of an order and the length may vary For example consider the lyrics of a song a sequence of words The idea of an order means that certain words naturally come before others It is e',\n","  'asy to remember the words in the normal order but much harder to recall the lyrics backwards In the real world sequences can be any kind of data of varying length and has a general idea of an order Some examples are texts audio recordings and video recordings Additionally we may want to use sequences in the input affair or indeed both in a machine learning operation Still it s challenging to perform computations on them with normal neural networks We cannot capture the idea of order and we don t know how numerous bumps will be demanded to represent a sequence Sequential data can be dealt with the sequenced neural networks which have a separate architecture To understand Recurrent neural network we will go with an example We need to predict the stock prices for a company using the neural network But there is some complication using the neural network as the stocks are not a random trend they change throughout their time Using regular neural network would cause complications in predicting the prices The data used in predicting the stocks would of course not be a static one so we need a neural network which would be good at dealing the dynamic change of data this is where recurrent neural networks comes to play Recurrent neural networks deals with the sequential data which help in dealing with the new data that enters by retraining using the feedback loops Feedback loops are the recurrent loop which calls them when they encounter a new data these feedback loops are present at every output of the activation function These activation functions output is fed to the previous nodes and weights are again updated in the process This makes it possible for the recurrent neural network possible to use the sequential input values prices collected over time to make predictions Recurrent neural network uses the current and past states to predict the tomorrow s case Unrolling the neural network would help us understand the working principle As from the above the diagram we can see that the output of the previous node is fed to the activation function and that output is used to feed the previous node including the next node This tells us that network can predict two values but the one that has currently occurred after the retrain with new weight The recurrence of the node can be given as the number of conditions that a particular problem has Based on these conditions the recurrent neural network s feedback loop runs The constants before any weight or biases should be controlled The number of times we unroll a recurrent neural network it gets harder to train the neural network this problem is called the Vanishing Gradient Problem As this has to with the squiggle that we copy each time we unroll the network To make it easier to understand the vanishing exploding gradient problem we re going to focus on the feedback loops weight Before finding the output in the RRN we first go with the residual value we then plug those gradients into the gradient descent algorithm to find the parameter values that maximizes loss function like sum of squared residuals LSTM is a stepping stone to learn about the Transformers LSTM is a type of vanilla recurrent neural network that was designed to overcome the problem of exploding vanishing gradient problem when unrolling the feedback networks the coefficients of the weights or biases happen to be increasing exponentially when the coefficients are greater than positive 1 the exponential increase causes the recurrent neural network to explode or if the coefficient is lesser than the 1 the exponential decrease tends to be much closer to zero which is known to be as the vanishing gradient problem To overcome this problem in recurrent neural network LSTM was introduced which had 2 different networks for storing the values stored long back and stored shortly This excludes the concept of feedback loops Instead of using the same feedback loop for the events that happened long ago and events that just happened yesterday to make a prediction about tomorrow LSTM uses two separate paths to make predictions about tomorrow '],\n"," '\\n',\n"," [['Text summarization is an NLP grounded fashion which involves converting large number of paragraphs into simple accessible judgment done by involving various grammatical connections sentence matching etc Analogy of the original paragraphs or texts is maintained. By text summarization we easily filter out the main context of any content provided and take meaning full actions with that summary. Summarization also helps dock the time demanded for reading fasten the hunt for information and help to get the most quantum of informati.'],\n","  ['Text summarization is a fascinating literacy content that caught attention fleetly as exploration increase. They present a neural model for single record summary dependent on joint extraction and pressure. This model picks sentences from the report and after that chooses which of a set of compression options to apply to each chosen sentence. They cipher this arrangement of separate contraction rules dependent on syntactic constituency parses still the proposed methodology is measured and it could use for any accessible source of condensing.'],\n","  ['Recurrent neural networks deal with the sequential data which help in dealing with the new data that enters by retraining using the feedback loops Feedback loops are the recurrent loop which calls them when they encounter a new data. The number of times we unroll a recurrent neural network it gets harder to train the neural network this problem is called the Vanishing Gradient Problem. LSTM was introduced which had 2 different networks for storing the values stored long back and stored shortly. This excludes the concept of feedback loops instead of using the same feedback loop for the events that happened long ago and events that just happened yesterday to make a prediction about tomorrow.']])"]},"metadata":{},"execution_count":22}]}]}